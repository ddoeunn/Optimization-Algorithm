{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Adaptive Regularization** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adaptive Learning Rate**  \n",
    "Consider an optimization problem which is axis-aligned, in which each coordinate is independent of the rest. It is reasonable to fine tune the learning rate for each coordinate separately - to achieve optimal convergence in that particular subspace of the problem, independently of the rest.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AdaGrad**  \n",
    "* learning rate decay  \n",
    ": Gradually reduce learning rates as learning progresses.  \n",
    "* Learning by adjusting learning rates adaptively to individual parameters. Variables that have not changed much change greatly and those that have changed a lot change only a little.  \n",
    "* By squaring the existing slope values and continuing to add them, the elements that move (largely updated) among the elements of the parameter make the learning rate low.\n",
    "\n",
    "#### **Algorithm (Full Matrix Version)**  \n",
    ">* Input : parameter $\\eta, \\mathbf{x}_1 \\in \\mathcal{K}$  \n",
    "* Initialize : $S_0 = G_0 = \\mathbb{0}$  \n",
    "* for $t=1$ to $T$ do:  \n",
    "    predict $\\mathbf{x}_t$, suffer loss $f_t(\\mathbf{x}_t)$  \n",
    "    update :   \n",
    "    $S_t = S_{t-1} + \\nabla_t\\nabla_t^T$,    $\\quad G_t = S_t^{\\frac{1}{2}}$  \n",
    "    $\\mathbf{y}_t = \\mathbf{x}_t - \\eta G_t^{-1}\\nabla_t$,      $\\quad \\mathbf{x}_{t+1} = argmin_{\\mathbf{x} \\in \\mathcal{K}} \\lVert \\mathbf{y}_{t+1}-\\mathbf{x} \\rVert ^2_{G_t}$  \n",
    "* end for  \n",
    "\n",
    "#### **Algorithm (Diagonal Version)**  \n",
    "* AdaGrad algorithm maintains potentially dense matrices. This is usually prohibitive in machine learning applications in which the dimension is very large. Diagonal version can be implemented in linear time and space, since diagonal matrices can be manupulated as vector.  \n",
    "*  update $S_t = S_{t-1} + diag(\\nabla_t\\nabla_t^T) $\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
